import { Injectable, Logger } from '@nestjs/common';
import OpenAI from 'openai';
import * as fs from 'fs';
import * as path from 'path';
import { randomUUID } from 'crypto';

@Injectable()
export class WhisperService {
  private readonly logger = new Logger(WhisperService.name);
  private openai: OpenAI | null = null;
  private useSimulation = true;

  constructor() {
    try {
      // OpenAI API í‚¤ê°€ ìˆìœ¼ë©´ ì‹¤ì œ Whisper API ì‚¬ìš©
      if (process.env.OPENAI_API_KEY) {
        this.openai = new OpenAI({
          apiKey: process.env.OPENAI_API_KEY,
        });
        this.useSimulation = false;
        this.logger.log('OpenAI Whisper API initialized');
      } else {
        this.logger.warn('OPENAI_API_KEY not found. Using simulation mode.');
        this.logger.warn('ì‹¤ì œ ìŒì„± ì¸ì‹ì„ ì‚¬ìš©í•˜ë ¤ë©´:');
        this.logger.warn('   1. OpenAI API í‚¤ ë°œê¸‰: https://platform.openai.com/api-keys');
        this.logger.warn('   2. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •: export OPENAI_API_KEY="sk-..."');
        this.logger.warn('   3. ì„œë²„ ì¬ì‹œì‘');
        this.useSimulation = true;
      }
    } catch (error) {
      this.logger.error('Failed to initialize OpenAI Whisper:', error);
      this.useSimulation = true;
    }
  }

  /**
   * ì˜¤ë””ì˜¤ ë²„í¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (Whisper API)
   */
  async transcribeAudio(audioBuffer: Buffer, languageCode: string = 'ko'): Promise<string> {
    if (this.useSimulation) {
      this.logger.warn('ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ: ì‹¤ì œ ìŒì„± ì¸ì‹ì„ ì‚¬ìš©í•˜ë ¤ë©´ OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”');
      return ''; // ì‹œë®¬ë ˆì´ì…˜ ìƒ˜í”Œ í…ìŠ¤íŠ¸ ì œê±°
    }

    try {
      // ì„ì‹œ íŒŒì¼ ìƒì„± (Whisper APIëŠ” íŒŒì¼ í•„ìš”)
      const tempDir = path.join(process.cwd(), 'temp');
      if (!fs.existsSync(tempDir)) {
        fs.mkdirSync(tempDir, { recursive: true });
      }

      const tempFilePath = path.join(tempDir, `audio_${randomUUID()}.m4a`);
      fs.writeFileSync(tempFilePath, audioBuffer);

      this.logger.log(`Whisper API í˜¸ì¶œ ì¤‘... (ì–¸ì–´: ${languageCode})`);

      // Whisper API í˜¸ì¶œ
      const transcription = await this.openai!.audio.transcriptions.create({
        file: fs.createReadStream(tempFilePath),
        model: 'whisper-1',
        language: languageCode === 'ko-KR' ? 'ko' : languageCode,
        response_format: 'text',
      });

      // ì„ì‹œ íŒŒì¼ ì‚­ì œ
      fs.unlinkSync(tempFilePath);

      const text = transcription.trim();
      
      if (text) {
        this.logger.log(`ìŒì„± ì¸ì‹ ì™„ë£Œ: ${text.substring(0, 50)}...`);
      } else {
          this.logger.warn('ìŒì„± ì¸ì‹ ê²°ê³¼ ì—†ìŒ (ì†Œë¦¬ê°€ ë„ˆë¬´ ì‘ê±°ë‚˜ ì—†ìŒ)');
      }

      return text;
    } catch (error: any) {
      this.logger.error('Whisper API ì—ëŸ¬:', error?.message);
      this.logger.error('ìƒì„¸ ì—ëŸ¬:', error);
      
      // ì—ëŸ¬ ë°œìƒ ì‹œ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜ (ì‹œë®¬ë ˆì´ì…˜ ì‚¬ìš© ì•ˆ í•¨)
      return '';
    }
  }

  /**
   * ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ: í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ í…ìŠ¤íŠ¸ ë°˜í™˜
   */
  private simulateTranscription(audioBuffer: Buffer): string {
    const sampleTexts = [
      'ì•ˆë…•í•˜ì„¸ìš”, ë°˜ê°‘ìŠµë‹ˆë‹¤.',
      'ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì •ë§ ì¢‹ë„¤ìš”.',
      'ì´ ì˜ìƒì´ ë§¤ìš° í¥ë¯¸ë¡­ìŠµë‹ˆë‹¤.',
      'ìë§‰ ì„œë¹„ìŠ¤ê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤.',
      'ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ í…ŒìŠ¤íŠ¸ ì¤‘ì…ë‹ˆë‹¤.',
      'ëª¨ë°”ì¼ ì•±ì—ì„œ ìë§‰ì„ í™•ì¸í•´ ë³´ì„¸ìš”.',
      'AllSub ì„œë¹„ìŠ¤ë¥¼ ì´ìš©í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤.',
      'ìŒì„± ì¸ì‹ ê¸°ëŠ¥ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.',
    ];

    // ì˜¤ë””ì˜¤ ë²„í¼ í¬ê¸°ì— ë”°ë¼ ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ë°˜í™˜
    const index = audioBuffer.length % sampleTexts.length;
    const text = sampleTexts[index];
    
    this.logger.log(`ğŸ­ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ: ${text}`);
    
    return text;
  }

  /**
   * í˜„ì¬ ëª¨ë“œ í™•ì¸
   */
  isUsingSimulation(): boolean {
    return this.useSimulation;
  }

  /**
   * ì„œë¹„ìŠ¤ ìƒíƒœ ì •ë³´
   */
  getStatus() {
    return {
      mode: this.useSimulation ? 'simulation' : 'whisper-api',
      apiKeyConfigured: !!process.env.OPENAI_API_KEY,
      ready: true,
    };
  }
}

